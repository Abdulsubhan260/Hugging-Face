{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCag_2t1-fJM"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3qRgKY34rud"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "raw_data=load_dataset(\"sms_spam\")\n",
        "\n",
        "# print(raw_data['train'][0])\n",
        "\n",
        "\n",
        "tokenizer=AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "  return tokenizer(examples['sms'],truncation=True,padding=\"max_length\",max_length=128)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tokenized_datasets=raw_data.map(preprocess_function,batched=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE5jb2L97wtd"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model_checkpoint='bert-base-uncased'\n",
        "\n",
        "num_labels=2\n",
        "\n",
        "\n",
        "model=AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    label2id={0:\"Ham\",1:\"spam\"},\n",
        "    num_labels=num_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjRLOCZi9C1G"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments,Trainer\n",
        "import numpy as np\n",
        "import evaluate\n",
        "# from evaluate import accuracy\n",
        "\n",
        "arg=TrainingArguments(\n",
        "    output_dir=\"bert_SpamDetector\",\n",
        "    learning_rate=0.00002,\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "\n",
        "split_dataset=tokenized_datasets['train'].train_test_split(test_size=0.2)\n",
        "metric=evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "\n",
        "    logits, labels = eval_pred\n",
        "\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "\n",
        "\n",
        "trainer=Trainer(\n",
        "    model=model,\n",
        "    args=arg,\n",
        "    train_dataset=split_dataset['train'],\n",
        "    eval_dataset=split_dataset['test'],\n",
        "    compute_metrics=compute_metrics\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJAVdjEzmn1e",
        "outputId": "1f8ff85f-8936-4c72-9c71-d02b4770f4d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- SPAM DETECTOR---\n",
            "Type 'quit' to exit.\n",
            "\n",
            "Enter a message: URGENT! You have won a $1000 cash prize. Call 0800-111-222 to claim now!\"\n",
            "Result: SPAM  (Alert!!!!!!!!)\n",
            "Confidence: 1.00%\n",
            "\n",
            "Enter a message: Click this link http://win-money.com to verify your account.\"\n",
            "Result: SPAM  (Alert!!!!!!!!)\n",
            "Confidence: 1.00%\n",
            "\n",
            "Enter a message: FREE ENTRY in our weekly competition.\"\n",
            "Result:  Not Spam (fair message)\n",
            "Confidence: 0.92%\n",
            "\n",
            "Enter a message: quit\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def predict_message(text):\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "\n",
        "\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "\n",
        "    pred_id = torch.argmax(probs).item()\n",
        "    confidence = probs[0][pred_id].item()\n",
        "\n",
        "\n",
        "    if pred_id == 1:\n",
        "        label = \"SPAM  (Alert!!!!!!!!)\"\n",
        "    else:\n",
        "        label = \" Not Spam (fair message)\"\n",
        "\n",
        "    return label, confidence\n",
        "\n",
        "print(\"--- SPAM DETECTOR---\")\n",
        "print(\"Type 'quit' to exit.\")\n",
        "\n",
        "while True:\n",
        "\n",
        "    user_text = input(\"\\nEnter a message: \")\n",
        "\n",
        "\n",
        "    if user_text.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "\n",
        "    prediction, confidence = predict_message(user_text)\n",
        "\n",
        "\n",
        "    print(f\"Result: {prediction}\")\n",
        "    print(f\"Confidence: {confidence:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}