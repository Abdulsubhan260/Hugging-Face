{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9epXZUfOUyPk"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TrainingArguments\n",
        "from transformers import AutoModelForSequenceClassification,Trainer\n",
        "raw_datasets=load_dataset(\"glue\",\"sst2\")\n",
        "tokenizer=AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "  return tokenizer(examples['sentence'],truncation=True,padding=\"max_length\")\n",
        "\n",
        "\n",
        "tokenized_datasets=raw_datasets.map(preprocess_function,batched=True)\n",
        "\n",
        "train_subset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "eval_subset = tokenized_datasets[\"validation\"].shuffle(seed=42).select(range(100))\n",
        "\n",
        "\n",
        "training_arg=TrainingArguments(\n",
        "    output_dir=\"./bert-sentiment\",\n",
        "    learning_rate=0.00002,\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model=model=AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=2)\n",
        "\n",
        "\n",
        "trainer=Trainer(\n",
        "    model=model,\n",
        "    args=training_arg,\n",
        "    train_dataset=train_subset,\n",
        "    eval_dataset=eval_subset\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "save_directory = \"./my_fine_tuned_bert\"\n",
        "trainer.save_model(save_directory)\n",
        "\n",
        "\n",
        "tokenizer.save_pretrained(save_directory)"
      ],
      "metadata": {
        "id": "zFKrjjECrzkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "\n",
        "load_directory = \"./my_fine_tuned_bert\"\n",
        "\n",
        "\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained(\"./my_fine_tuned_bert\")\n",
        "\n",
        "\n",
        "loaded_model = AutoModelForSequenceClassification.from_pretrained(\"./my_fine_tuned_bert\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Model loaded successfully\")"
      ],
      "metadata": {
        "id": "wLE29chA0sjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def predict_sentiment(text):\n",
        "\n",
        "    inputs = loaded_tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = loaded_model(**inputs)\n",
        "\n",
        "\n",
        "    logits = outputs.logits\n",
        "\n",
        "\n",
        "    predicted_class_id = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "\n",
        "    labels = [\"Negative\", \"Positive\"]\n",
        "    return labels[predicted_class_id]\n",
        "\n",
        "\n",
        "print(predict_sentiment(\"I love to learn about new things\"))\n",
        "print(predict_sentiment(\"he is not satisfied\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqJE9G8e2ytr",
        "outputId": "1ceffad6-2c79-4c69-ef64-e2c10bf2d7c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n",
            "Negative\n"
          ]
        }
      ]
    }
  ]
}